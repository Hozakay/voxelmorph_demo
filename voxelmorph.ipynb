{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Unsupervised Deep Learning Registration\n",
    "[Adrian Dalca](http://adalca.mit.edu) for the [learn2reg 2019 tutorial](http://learn2reg.github.io)\n",
    "\n",
    "Unsupervised is also often referred to end-to-end/self-supervised\n",
    "\n",
    "Please first run this jupyter notebook *within kaggle*, since all the paths and data have been set up.  \n",
    "\n",
    "### Outline\n",
    "- **Core concepts with MNIST**   \n",
    "We will first learn to deal with data, building a model, training, registration and generalization\n",
    "- **More realistic complexity: Brain MRI (2D slices)**  \n",
    "We will then show how these models work for 2d slices of brain scans, presenting a more complex scenario    \n",
    "- **Realistic 3D Brain MRI**  \n",
    "We will illustrate full 3D registration\n",
    "- **Advances topics**  \n",
    "Finally, we close with more advanced topics, including diffeomorphisms and fine-tuning deformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we assume that the images have been rigidly aligned in a (roughly) similar space.  \n",
    "Rigid alignment is also possible with unsupervised learning-based registration, but it's not our focus here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "A good chunk of this tutorial build on work from [voxelmorph](https://github.com/voxelmorph/voxelmorph) ([TMI](https://arxiv.org/abs/1809.05231) and [MedIA](https://arxiv.org/abs/1903.03545)) and code from [neuron](https://github.com/adalca/neuron) ([CVPR](http://arxiv.org/abs/1903.03148))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "tensorflow==1.14  \n",
    "keras  \n",
    "nibabel  \n",
    "scipy  \n",
    "tqdm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "## Setup of environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with some common imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflow==1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import two packages that will help us   \n",
    "- [neuron](https://github.com/adalca/neuron) is a library for medical image analysis with tensorflow  \n",
    "- [voxelmorph](http://voxelmorph.mit.edu) is a deep-learning based registration library  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports.\n",
    "from pathlib import Path\n",
    "sys.path.append('voxelmorph/ext/pynd-lib/')\n",
    "sys.path.append('voxelmorph/ext/pytools-lib/')\n",
    "sys.path.append('voxelmorph/ext/neuron/')\n",
    "sys.path.append('voxelmorph/')\n",
    "import voxelmorph as vxm\n",
    "import neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by registering 2D MNIST digits, and then move on to medical data later.  \n",
    "If the data is small (like 2D MNIST), you can often load it in memory, which enables for faster training and testing.  \n",
    "If the data is large (large 3D scans), we will need to load the scans on demand. More on this later...\n",
    "\n",
    "First, we're going to **load the data**  \n",
    "Luckily, MNIST comes with the keras framework, so we can just load it here as follows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "# You should most often have this import together with all other imports at the top, \n",
    "# but we include here here explicitly to show where data comes from\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data. \n",
    "# `mnist.load_data()` already splits our data into train and test.  \n",
    "# (x_train_load, y_train_load), (x_test_load, y_test_load) = mnist.load_data()\n",
    "\n",
    "# unfortunately the above seems to fail on the keras kernel\n",
    "# so we will load it from a pre-downloaded mnist numpy file\n",
    "mnist_file = 'mnist/mnist.npz'\n",
    "x_train_load = np.load(mnist_file)['x_train']\n",
    "y_train_load = np.load(mnist_file)['y_train']\n",
    "x_test_load = np.load(mnist_file)['x_test']\n",
    "y_test_load = np.load(mnist_file)['y_test']\n",
    "\n",
    "# extract only instances of the digit 5\n",
    "x_train = x_train_load[y_train_load==5, ...]\n",
    "y_train = y_train_load[y_train_load==5]\n",
    "x_test = x_test_load[y_test_load==5, ...]\n",
    "y_test = y_test_load[y_test_load==5]\n",
    "\n",
    "# let's get some shapes to understand what we loaded.\n",
    "print('shape of x_train: ', x_train.shape)\n",
    "print('shape of y_train: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that separating your data in *only* train/test **often leads to problems**   \n",
    "You wouldn't want to iteratively (A) build a model, (B) train on training data, and (C) test on test data  \n",
    "Doing so will **overfit to you test set** (because you will have adapted your algorithm to your test data  \n",
    "\n",
    "We will split the 'training' into 'train/validate' data, and keep the test set for later  \n",
    "And will only look at the test data at the very end (once we're ready to submit the paper!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_val = 1000 # keep 10,000 subjects for validation\n",
    "x_val = x_train[-nb_val:, ...]  # this indexing means \"the last nb_val entries\" of the zeroth axis\n",
    "y_val = y_train[-nb_val:]\n",
    "x_train = x_train[:-nb_val, ...]\n",
    "y_train = y_train[:-nb_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Believeing we are done loading, it's always great to visualize the data  \n",
    "Here, we use some tools from a package called `neuron`, which uses matplotlib  \n",
    "You could use matplotlib as well directly, but it would just be a bit messier  \n",
    "and here we want to illustrate the main concepts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vis = 5\n",
    "\n",
    "# choose nb_vis sample indexes\n",
    "idx = np.random.choice(x_train.shape[0], nb_vis, replace=False)\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "\n",
    "# plot\n",
    "neuron.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  \n",
    "\n",
    "However, luckily we included a **colorbar**, which shows us that the data is in [0, 255].  \n",
    "In neural networks it's often great to work in the ranges of [0, 1] or [-1, 1] or around there.  \n",
    "Let's fix this. \n",
    "\n",
    "In general, you should always plot your data with colorbars, which helps you catch issues before training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix data\n",
    "x_train = x_train.astype('float')/255\n",
    "x_val = x_val.astype('float')/255\n",
    "x_test = x_test.astype('float')/255\n",
    "\n",
    "# verify\n",
    "print('training maximum value', x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-visualize\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "neuron.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last change. Later on, we'll see that some of the most popular models  \n",
    "like to have inputs that are sized as multiples of 2^N for N being the number of layers  \n",
    "Here, we force our images to be size 32 (2x 2^4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_amount = ((0, 0), (2,2), (2,2))\n",
    "\n",
    "# fix data\n",
    "x_train = np.pad(x_train, pad_amount, 'constant')\n",
    "x_val = np.pad(x_val, pad_amount, 'constant')\n",
    "x_test = np.pad(x_test, pad_amount, 'constant')\n",
    "\n",
    "# verify\n",
    "print('shape of training data', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two images, out goal is to find the deformation between them  \n",
    "\n",
    "In learning-based methods, we use a network that takes in two images $m$ and $f$ (e.g. MNIST digits of size 32x32)    \n",
    "and outputs a dense deformation $\\phi$ (e.g. size 32x32x2, because at each pixel we want a vector telling us where to go)  \n",
    "\n",
    "**Note**: registration also includes (or refers to) affine transforms, but we ignore that here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to abstract the UNet for this tutorial and use a function from [voxelmorph](http://voxelmorph.mit.edu)  \n",
    "`vxm.networks.unet_core()` enables this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndims = 2\n",
    "vol_shape = x_train.shape[1:]\n",
    "nb_enc_features = [32, 32, 32, 32]\n",
    "nb_dec_features = [32, 32, 32, 32, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's get a unet (before the final layer)\n",
    "unet = vxm.networks.unet_core(vol_shape, nb_enc_features, nb_dec_features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's explore the model bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "print('numer of inputs', len(unet.inputs))\n",
    "moving_input_tensor = unet.inputs[0]\n",
    "fixed_input_tensor = unet.inputs[1]\n",
    "    \n",
    "# output\n",
    "print('output:', unet.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, we need to make sure the final output has 2 features,  \n",
    "representing the deformation at each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the results into a flow field.\n",
    "disp_tensor = keras.layers.Conv2D(ndims, kernel_size=3, padding='same', name='disp')(unet.output)\n",
    "\n",
    "# check\n",
    "print('displacement tensor:', disp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a cool aspect of keras is that we can easily form new models via tensor pointers:\n",
    "def_model = keras.models.Model(unet.inputs, disp_tensor)\n",
    "# def_model will now *share layers* with the UNet -- if we change layer weights \n",
    "# in the UNet, they change in the def_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the displacement $\\phi$ is output from the network,  \n",
    "we need to figure out a loss to tell if it makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a **supervised setting** we would have ground truth deformations $\\phi_{gt}$,  \n",
    "and we could use a supervised loss like MSE $= \\| \\phi - \\phi_{gt} \\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea in **unsupervised registration** is to use loss inspired by classical registration  \n",
    "\n",
    "Without supervision, how do we know this deformation is good?  \n",
    "(1) make sure that $m \\circ \\phi$ ($m$ warped by $\\phi$) is close to $f$  \n",
    "(2) regularize $\\phi$ (often meaning make sure it's smooth)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve (1), we need to *warp* input image $m$.  \n",
    "To do this, we use a spatial transformation network layer, which essentially does linear interpolation  \n",
    "This layer is defined in [neuron](https://github.com/adalca/neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_transformer = neuron.layers.SpatialTransformer(name='spatial_transformer')\n",
    "\n",
    "# warp the image\n",
    "moved_image_tensor = spatial_transformer([moving_input_tensor, disp_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the moved_image is close to the fixed image, and  \n",
    "to achieve smoothness loss of $\\phi$ in (2), we will want these two as outputs from the full model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [moving_input_tensor, fixed_input_tensor]\n",
    "outputs = [moved_image_tensor, disp_tensor]\n",
    "vxm_model = keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define the actual loss. The way keras works, we need to define a loss for each output.    \n",
    "The first loss is easy, it's simply MSE between the warped image $m \\circ \\phi$.\n",
    "For the second, we will use a spatial gradient of the displacement.  \n",
    "We won't code this from scratch here, but we'll use the `voxelmorph` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses. Keras recognizes the string 'mse' as mean squared error, so we don't have to code it\n",
    "losses = ['mse', vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter.\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compile the model. \n",
    "This sets up the model for training, by associating the model with a loss and an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train, we need to make sure the data is in the right format and fed to the model the way we want it  \n",
    "keras models can be trained with `model.fit`, which requires all the data to be in a big array, or `model.fit_generator`, which requires a python generator that gives you batches of data\n",
    "\n",
    "Let's code a simple data generator based on the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vxm_data_generator(x_data, batch_size=32):\n",
    "    \"\"\"\n",
    "    generator that takes in data of size [N, H, W], and yields data for our vxm model\n",
    "    \n",
    "    Note that we need to provide numpy data for each input, and each output\n",
    "    \n",
    "    inputs:  moving_image [bs, H, W, 1], fixed_image [bs, H, W, 1]\n",
    "    outputs: moved_image  [bs, H, W, 1], zeros [bs, H, W, 2]\n",
    "    \"\"\"\n",
    "    # preliminary sizing\n",
    "    vol_shape = x_data.shape[1:] # extract data shape\n",
    "    ndims = len(vol_shape)\n",
    "    \n",
    "    # prepare a zero array the size of the deformation. We'll explain this below.\n",
    "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
    "    \n",
    "    while True:\n",
    "        # prepare inputs\n",
    "        # inputs need to be of the size [batch_size, H, W, number_features]\n",
    "        #   number_features at input is 1 for us\n",
    "        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
    "        moving_images = x_data[idx1, ..., np.newaxis]\n",
    "        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
    "        fixed_images = x_data[idx2, ..., np.newaxis]\n",
    "        inputs = [moving_images, fixed_images]\n",
    "        \n",
    "        # outputs\n",
    "        # we need to prepare the \"true\" moved image.  \n",
    "        # Of course, we don't have this, but we know we want to compare \n",
    "        # the resulting moved image with the fixed image. \n",
    "        # we also wish to penalize the deformation field. \n",
    "        outputs = [fixed_images, zero_phi]\n",
    "        \n",
    "        yield inputs, outputs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = vxm_data_generator(x_train)\n",
    "input_sample, output_sample = next(train_generator)\n",
    "\n",
    "# visualize\n",
    "slices_2d = [f[0,...,0] for f in input_sample + output_sample]\n",
    "titles = ['input_moving', 'input_fixed', 'output_moved_ground_truth', 'zero']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "steps_per_epoch = 100\n",
    "hist = vxm_model.fit_generator(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to visualize the loss, not just read off the numbers  \n",
    "This will give us a better idea of whether it's converged, etc.  \n",
    "Tensorflow offers a powerful interactive system for visualizing called tensorboard  \n",
    "For this short tutorial, we will simply plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as with other imports, this import should be at the top, or use notebook matplotlib magic\n",
    "# we keep it here to be explicit why we need it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(hist, loss_name='loss'):\n",
    "    \"\"\"\n",
    "    Quick function to plot the history \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(hist.epoch, hist.history[loss_name], '.-')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is not converged, and you should run it to convergence.  \n",
    "For the purposes of this tutorial, we'll move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pair-wise optimization methods (like most classical methods),  \n",
    "to register a new pair you would need to optimize a deformation field.  \n",
    "\n",
    "With learning based registration, we simply evaluate the network for a new input pair  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get some data\n",
    "val_generator = vxm_data_generator(x_val, batch_size = 1)\n",
    "val_input, _ = next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Registration*: `predict()` essentially executes the network given an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and that's it! \n",
    "\n",
    "Even though this is on MNIST only, let's see how long this takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit is a 'jupyter magic' that times the given line over several runs\n",
    "%timeit vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~3ms per registration is quite fast, even for MNIST.  \n",
    "Let's visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "slices_2d = [f[0,...,0] for f in val_input + val_pred]\n",
    "titles = ['input_moving', 'input_fixed', 'predicted_moved', 'deformation_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the flow a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.plot.flow([val_pred[1].squeeze()], width=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization \n",
    "How do learning-based methods generalize beyond training distribution ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important caveat to learning-based registration is that  \n",
    "They will, in general, only register samples fromt he distribution they've been trained from  \n",
    "\n",
    "So, what happens if we register two 7s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only instances of the digit 5\n",
    "x_sevens = x_train_load[y_train_load==7, ...].astype('float')/255\n",
    "x_sevens = np.pad(x_sevens, pad_amount, 'constant')\n",
    "\n",
    "seven_generator = vxm_data_generator(x_sevens, batch_size=1)\n",
    "seven_sample, _ = next(seven_generator)\n",
    "seven_pred = vxm_model.predict(seven_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "slices_2d = [f[0,...,0] for f in seven_sample + seven_pred]\n",
    "titles = ['input_moving', 'input_fixed', 'predicted_moved', 'deformation_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interesting, it still works! So it **generalized beyond what we expected**. Why?  \n",
    "Locally, parts of the 7s look similar to the 5s, so the  registration algorithm still tries to match local neighborhoods.\n",
    "\n",
    "Let's try a different variation.  \n",
    "What if we just modify the (original) set, but multiplied the intensities by a factor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 5\n",
    "val_pred = vxm_model.predict([f*factor for f in val_input])\n",
    "\n",
    "# visualizeb\n",
    "slices_2d = [f[0,...,0] for f in val_input + val_pred]\n",
    "titles = ['input_moving', 'input_fixed', 'predicted_moved', 'deformation_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This broke down! Why? In this case, the network has never seen even parts of this image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding when the network generalizes and when it does not is very important, and still a part of active research  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration of Brain MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now register slightly more realistic data: MRIs of the brain.  \n",
    "To be able to train and easily register during this tutorial,  \n",
    "we will first extract the middle slice of brain scans. \n",
    "\n",
    "Nothat because this task does not capture deformations in the third dimensions,  \n",
    "certain  correspondances are not exactly possible.  Nonetheless, this exercise  \n",
    "will illustrate registration with more realistic complex images.   \n",
    "\n",
    "The brains have been intensity-normalized affinely aligned, and skull stripped  \n",
    "with FreeSurfer, to enable focusing on deformable registration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've prepared the data in the following files\n",
    "# prepared as N x H x W\n",
    "core_path = 'mri-2d/'\n",
    "x_train = np.load(os.path.join(core_path, 'train_vols.npy'))\n",
    "x_val = np.load(os.path.join(core_path, 'validate_vols.npy'))\n",
    "# x_test = np.load(os.path.join(core_path, 'test_vols.npy'))\n",
    "\n",
    "vol_shape = x_train.shape[1:]\n",
    "print('train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 208 volumes are of size `160x192`.  \n",
    "Let's look at some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some brains\n",
    "nb_vis = 5\n",
    "idx = np.random.randint(0, x_train.shape[0], [5,])\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "\n",
    "# visualize\n",
    "neuron.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we create a model based on a unet, plus a spatial transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet\n",
    "unet = vxm.networks.unet_core(vol_shape, nb_enc_features, nb_dec_features);\n",
    "disp_tensor = keras.layers.Conv2D(ndims, kernel_size=3, padding='same', name='disp')(unet.output)\n",
    "\n",
    "# spatial transfomer\n",
    "spatial_transformer = neuron.layers.SpatialTransformer(name='image_warping')\n",
    "moved_image_tensor = spatial_transformer([unet.inputs[0], disp_tensor])\n",
    "\n",
    "# final model\n",
    "vxm_model = keras.models.Model(unet.inputs, [moved_image_tensor, disp_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with MNIST, we'll start with losses of 'mse' and spatial smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses. Keras recognizes the string 'mse' as mean squared error, so we don't have to code it\n",
    "losses = ['mse', vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter.\n",
    "lambda_param = 0.01\n",
    "loss_weights = [1, lambda_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from experimentation, we have found the Adam optimizer learning rate of `1e-4`  \n",
    "performs better than `1e-3` for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we can use the same generator as before, since we're using the same format.  \n",
    "Let's test it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = vxm_data_generator(x_train, batch_size=8)\n",
    "input_sample, output_sample = next(train_generator)\n",
    "\n",
    "# visualize\n",
    "slices_2d = [f[0,...,0] for f in input_sample + output_sample]\n",
    "titles = ['input_moving', 'input_fixed', 'output_sample_true', 'zero']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, time to **train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "steps_per_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = vxm_model.fit_generator(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the purpose of the tutorial we ran very few epochs.  \n",
    "# Here we load a model that was run for 10 epochs and 100 steps per epochs\n",
    "vxm_model.load_weights('unsupervised-models/brain_2d_shortrun.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before, let's visualize what happened\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = vxm_data_generator(x_val, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input, _ = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "slices_2d = [f[0,...,0] for f in val_input + val_pred]\n",
    "titles = ['input_moving', 'input_fixed', 'predicted_moved', 'deformation_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = val_pred[1].squeeze()[::3,::3]\n",
    "neuron.plot.flow([flow], width=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's save out model weights, we'll use them in a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.save_weights('brain_2d_shortrun.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating registration results is tricky.  \n",
    "The first tendancy is to look at the images (as above),  \n",
    "and conclude that if they match, The registration has succeeded. \n",
    "\n",
    "However, this can be achieved by an optimization that only penalizes the image matching term  \n",
    "For example, in the next cell we compare our model with one that wastrained on maximizing MSE only (no smoothness loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.load_weights('unsupervised-models/brain_2d_shortrun.h5')\n",
    "our_val_pred = vxm_model.predict(val_input)\n",
    "\n",
    "vxm_model.load_weights('unsupervised-models/brain_2d_mseonly.h5')\n",
    "mse_val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize both models\n",
    "slices_2d = [f[0,...,0] for f in [val_input[1]] + our_val_pred ]\n",
    "titles = ['input_fixed', 'our_pred_moved', 'our_disp_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);\n",
    "\n",
    "# visualize both models\n",
    "slices_2d = [f[0,...,0] for f in [val_input[1]] + mse_val_pred]\n",
    "titles = ['input_fixed', 'mse_pred_moved', 'mse_pred_x']\n",
    "neuron.plot.slices(slices_2d, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.plot.flow([f[1].squeeze()[::3,::3] for f in [our_val_pred, mse_val_pred]], width=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first look, the mse-only model matches the fixed image better  \n",
    "But we can see that it obtains a deformation field that is very noisy, unlikely to be anatomically meaningful  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we often do isntead of use **external anotations** for evaluation  \n",
    "One way is using anatomical segmentations.  \n",
    "\n",
    "In the next section, we demonstrate the use of a 3D model, and show how to evaluate it with segmentations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cells deactivated since kernel is shutting down due to unknown error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D MRI brain scan registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get to 3D models, which are of particular interest in medical image analysis. \n",
    "\n",
    "However, due to the size of the models and data, we won't be able to train a model  \n",
    "within a short tutorial time. Instead, here we assume one has been trained, and demonstrate its use.\n",
    "You can train one very similar to how you trained the 2D models above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our data will be of shape 160 x 192 x 224\n",
    "vol_shape = [160, 192, 224]\n",
    "ndims = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_enc_features = [16, 32, 32, 32]\n",
    "nb_dec_features = [32, 32, 32, 32, 32, 16, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unet\n",
    "unet = vxm.networks.unet_core(vol_shape, nb_enc_features, nb_dec_features);\n",
    "disp_tensor = keras.layers.Conv3D(ndims, kernel_size=3, padding='same', name='disp')(unet.output)\n",
    "\n",
    "# spatial transfomer\n",
    "spatial_transformer = neuron.layers.SpatialTransformer(name='image_warping')\n",
    "moved_image_tensor = spatial_transformer([unet.inputs[0], disp_tensor])\n",
    "\n",
    "# final model\n",
    "vxm_model = keras.models.Model(unet.inputs, [moved_image_tensor, disp_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_volume_1 = np.load('mri-3d/subject_1_vol.npz')['vol_data']\n",
    "seg_volume_1 = np.load('mri-3d/subject_1_seg.npz')['vol_data']\n",
    "val_volume_2 = np.load('mri-3d/atlas_norm_3d.npz')['vol']\n",
    "seg_volume_2 = np.load('mri-3d/atlas_norm_3d.npz')['seg']\n",
    "\n",
    "\n",
    "val_input = [val_volume_1[np.newaxis, ..., np.newaxis], val_volume_2[np.newaxis, ..., np.newaxis]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a trained 3D model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vxm_model.load_weights('unsupervised-models/cvpr2018_vm2_cc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_pred = vxm_model.predict(val_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moved_pred = val_pred[0].squeeze()\n",
    "pred_warp = val_pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mid_slices_fixed = [np.take(val_volume_2, vol_shape[d]//2, axis=d) for d in range(ndims)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(moved_pred, vol_shape[d]//2, axis=d) for d in range(ndims)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "neuron.plot.slices(mid_slices_fixed + mid_slices_pred, cmaps=['gray'], do_colorbars=True, grid=[2,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the segmentations! To do this, we'll need to warp segmentations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "warp_model = vxm.networks.nn_trf(vol_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "warped_seg = warp_model.predict([seg_volume_1[np.newaxis,...,np.newaxis], pred_warp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're first going to prepare a colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pytools import plotting as pytools_plot\n",
    "import matplotlib\n",
    "\n",
    "[ccmap, scrambled_cmap] = pytools_plot.jitter(255, nargout=2)\n",
    "scrambled_cmap[0, :] = np.array([0, 0, 0, 1])\n",
    "ccmap = matplotlib.colors.ListedColormap(scrambled_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the segmentations, and essentially make sure they are not crazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mid_slices_fixed = [np.take(seg_volume_1, vol_shape[d]//1.8, axis=d) for d in range(ndims)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(warped_seg.squeeze(), vol_shape[d]//1.8, axis=d) for d in range(ndims)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "\n",
    "slices = mid_slices_fixed + mid_slices_pred\n",
    "for si, slc  in enumerate(slices):\n",
    "    slices[si][0] = 255\n",
    "neuron.plot.slices(slices, cmaps = [ccmap], grid=[2,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important advantage of learning-based methods is the dramatically lowered runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%timeit vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our tests, a run is 10s, for an entire 3D volume.  \n",
    "Classically, this would take hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
